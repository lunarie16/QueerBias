%%
%% Abstract
%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section*{Abstract}
This thesis explores the latent effects of biases related to sexual identity and orientation in generative models of \acrfull{ai}, with a focus on \acrfull{llms} like Mistral. As AI systems increasingly permeate various aspects of daily life, understanding and mitigating biases within them becomes crucial to ensuring they serve society equitably. This study specifically investigates the potential of soft-prompt tuning \citep{prompt-tuning}, as opposed to traditional fine-tuning methods, for identifying and reducing biases in \acrshort{llms} concerning sexual identity and preference/orientation. Through a combination of quantitative and qualitative analyses, including the use of datasets like HolisticBias \citep{holistic} and WinoQueer \citep{winoqueer}, this research aims to shed light on the presence of biases in \acrshort{llms} and evaluate the effectiveness of soft-prompt tuning as a bias mitigation strategy.

The findings reveal significant latent biases within the tested \acrshort{llm}, which manifest in skewed representations and treatments of content related to sexual identity. The application of soft-prompt tuning demonstrates a notable reduction in these biases, showcasing its potential as a viable and less resource-intensive alternative to traditional fine-tuning methods for bias mitigation. This thesis contributes to the growing body of knowledge on \acrshort{ai} ethics by providing empirical evidence of the effectiveness of soft-prompt tuning in addressing sexual identity biases in \acrshort{llms} and by offering insights into the broader implications of bias in AI systems.

This research underscores the importance of developing and implementing innovative techniques for bias detection and mitigation in \acrshort{ai}. By highlighting the potential of soft-prompt tuning to create more inclusive and equitable \acrshort{ai} systems, this study calls for further exploration into alternative methods of bias mitigation and stresses the need for continuous vigilance and intervention by \acrshort{ai} developers, researchers, and policymakers to address biases in \acrshort{ai} technologies.

\vspace{3cm}

\textbf{\textit{Keywords: }}Artificial Intelligence, Large Language Models, Bias Mitigation, Soft-Prompt Tuning, Sexual Identity, AI Ethics

%% eof
